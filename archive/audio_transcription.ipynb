{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "from utils.load_reference_files_utils import *\n",
    "from utils.search_engine_utils import *\n",
    "from utils.general_utils import *\n",
    "from utils.generated_answer_utils import *\n",
    "from utils.classifier_utils import *\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_KEY  = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration for the \"local\" environment\n",
    "with open('../config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)[\"local\"]\n",
    "    filepaths = config['filepaths']\n",
    "    embedding_params = config['embedding_params']\n",
    "    classifier_params = config['classifier_params']\n",
    "    semantic_search_params = config['semantic_search_params']\n",
    "    generated_answer_params = config['generated_answer_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio transcription libraries\n",
    "from faster_whisper import WhisperModel\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using speech_recognition library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "# # obtain audio from the microphone\n",
    "# with sr.Microphone() as source:\n",
    "#     print(\"Say something!\")\n",
    "#     audio = r.listen(source)\n",
    "\n",
    "# obtain audio from file\n",
    "audio_path = \"../data/recordings/sample_fruit_audio_2.wav\"\n",
    "with sr.AudioFile(audio_path) as source:\n",
    "    audio = r.record(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx thinks you said thank you for providing those information not start at me just gave me you are keen to answer that we know what they're going to do before publisher being we have an option to rest at the apple haiti astrid using the settings of your devices and that doesn't work we can resent that is refusing of borrowed apple of advice and asked me if that's still doesn't work will you still have to respect your password\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Sphinx\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition thinks you said thank you for providing those information not start let me just give you our game plan so that we know what were going to do before troubleshooting we have an option to reset the apple id password using the settings of your device if that doesn't work we can reset the password using a borrowed apple device and last day if that still doesn't work we will use the web to reset your password\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using Google Speech Recognition\n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper thinks you said  Thank you for providing those information. Now to start, let me just give you our game plans so that we know what we're going to do before troubleshooting. We have an option to reset the Apple ID password using the settings of your device. If that doesn't work, we can reset the password using a borrowed Apple device. And lastly, if that still doesn't work, we will use the web to reset your password.\n"
     ]
    }
   ],
   "source": [
    "# recognize speech using whisper\n",
    "try:\n",
    "    print(\"Whisper thinks you said \" + r.recognize_whisper(audio, language=\"english\"))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Whisper could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Whisper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\canepomuceno\\OneDrive - TDCX (SG) Pte. Ltd\\Documents\\Local-IDE\\Fruit-KB\\POC_knowledge_graph\\audio_transcription.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# recognize speech using Whisper API\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# OPENAI_API_KEY = \"INSERT OPENAI API KEY HERE\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhisper API thinks you said \u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m.\u001b[39;49mrecognize_whisper_api(audio,\u001b[39m \u001b[39;49mapi_key\u001b[39m=\u001b[39;49mOPENAI_API_KEY)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m sr\u001b[39m.\u001b[39mRequestError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/canepomuceno/OneDrive%20-%20TDCX%20%28SG%29%20Pte.%20Ltd/Documents/Local-IDE/Fruit-KB/POC_knowledge_graph/audio_transcription.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCould not request results from Whisper API\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\speech_recognition\\recognizers\\whisper.py:41\u001b[0m, in \u001b[0;36mrecognize_whisper_api\u001b[1;34m(recognizer, audio_data, model, api_key)\u001b[0m\n\u001b[0;32m     38\u001b[0m wav_data \u001b[39m=\u001b[39m BytesIO(audio_data\u001b[39m.\u001b[39mget_wav_data())\n\u001b[0;32m     39\u001b[0m wav_data\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSpeechRecognition_audio.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 41\u001b[0m transcript \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mAudio\u001b[39m.\u001b[39;49mtranscribe(model, wav_data, api_key\u001b[39m=\u001b[39;49mapi_key)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m transcript[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\openai\\api_resources\\audio.py:67\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     55\u001b[0m requestor, files, data \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_prepare_request(\n\u001b[0;32m     56\u001b[0m     file\u001b[39m=\u001b[39mfile,\n\u001b[0;32m     57\u001b[0m     filename\u001b[39m=\u001b[39mfile\u001b[39m.\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_url(\u001b[39m\"\u001b[39m\u001b[39mtranscriptions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, files\u001b[39m=\u001b[39;49mfiles, params\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m     68\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     69\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[0;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    597\u001b[0m         method,\n\u001b[0;32m    598\u001b[0m         abs_url,\n\u001b[0;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:1394\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[0;32m   1393\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m-> 1394\u001b[0m     response\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m   1395\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:417\u001b[0m, in \u001b[0;36mHTTPResponse.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     fp\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    418\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mclose() \u001b[39m# set \"closed\" flag\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# recognize speech using Whisper API\n",
    "# OPENAI_API_KEY = \"INSERT OPENAI API KEY HERE\"\n",
    "try:\n",
    "    print(f\"Whisper API thinks you said {r.recognize_whisper_api(audio, api_key=OPENAI_API_KEY)}\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Whisper API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_transcriber(audio=None, type=\"path\", model=\"tiny.en\"):\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    if type==\"path\":\n",
    "        with sr.AudioFile(audio) as source:\n",
    "            audio = r.record(source)\n",
    "    elif type==\"numpy\":\n",
    "        pass\n",
    "    elif type==\"microphone\":\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Say something!\")\n",
    "            audio = r.listen(source, timeout=2, phrase_time_limit=3)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_whisper(audio, model=model, language=\"english\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Sorry, could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Error with the speech recognition service; {e}\"\n",
    "    except AssertionError:\n",
    "        return \"No audio to transcribe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hi, I want to describe this one.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_transcriber(type=\"microphone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_whisper_transcriber(audio, type=\"path\", model=\"tiny.en\"):\n",
    "    # Run on GPU with FP16\n",
    "    # model = WhisperModel(model, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "    # or run on GPU with INT8\n",
    "    # model = WhisperModel(model, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "\n",
    "    # or run on CPU with INT8\n",
    "    model = WhisperModel(model, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "    if type==\"path\":\n",
    "        segments, _ = model.transcribe(audio, beam_size=5)\n",
    "        for segment in segments:\n",
    "            print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "            print(segment.text)\n",
    "            # print(type(segment.text))\n",
    "    elif type==\"numpy\":\n",
    "        pass\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thank you for providing those information, not start, let me just give you our game plan\n",
      " so that we know what we're going to do before troubleshooting.\n",
      " We have an option to reset the Apple ID password using the settings of your device.\n",
      " If that doesn't work, we can reset the password using a borrowed Apple device.\n",
      " And lastly, if that still doesn't work, we will use the web to reset your password.\n"
     ]
    }
   ],
   "source": [
    "segments = faster_whisper_transcriber(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio demo using Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "demo = gr.Interface(\n",
    "    whisper_transcriber,\n",
    "    [gr.Audio(source=\"microphone\", type=\"filepath\", format=\"wav\")],\n",
    "    # [gr.Audio(source=\"microphone\", type=\"numpy\")],\n",
    "    [\"text\"]\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio demo using Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\routes.py\", line 516, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\route_utils.py\", line 219, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1437, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\utils.py\", line 650, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\canepomuceno\\AppData\\Local\\Temp\\ipykernel_26968\\2106592707.py\", line 5, in whisper_transcriber\n",
      "    with sr.AudioFile(audio) as source:\n",
      "         ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\speech_recognition\\__init__.py\", line 226, in __init__\n",
      "    assert isinstance(filename_or_fileobject, (type(\"\"), type(u\"\"))) or hasattr(filename_or_fileobject, \"read\"), \"Given audio file must be a filename string or a file-like object\"\n",
      "AssertionError: Given audio file must be a filename string or a file-like object\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\routes.py\", line 516, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\route_utils.py\", line 219, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1437, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\utils.py\", line 650, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\canepomuceno\\AppData\\Local\\Temp\\ipykernel_26968\\2106592707.py\", line 5, in whisper_transcriber\n",
      "    with sr.AudioFile(audio) as source:\n",
      "         ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\speech_recognition\\__init__.py\", line 226, in __init__\n",
      "    assert isinstance(filename_or_fileobject, (type(\"\"), type(u\"\"))) or hasattr(filename_or_fileobject, \"read\"), \"Given audio file must be a filename string or a file-like object\"\n",
      "AssertionError: Given audio file must be a filename string or a file-like object\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\routes.py\", line 516, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\route_utils.py\", line 219, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1437, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\blocks.py\", line 1109, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\gradio\\utils.py\", line 650, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\canepomuceno\\AppData\\Local\\Temp\\ipykernel_26968\\2106592707.py\", line 5, in whisper_transcriber\n",
      "    with sr.AudioFile(audio) as source:\n",
      "         ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\fruit-kb-QON9TVu_-py3.11\\Lib\\site-packages\\speech_recognition\\__init__.py\", line 226, in __init__\n",
      "    assert isinstance(filename_or_fileobject, (type(\"\"), type(u\"\"))) or hasattr(filename_or_fileobject, \"read\"), \"Given audio file must be a filename string or a file-like object\"\n",
      "AssertionError: Given audio file must be a filename string or a file-like object\n"
     ]
    }
   ],
   "source": [
    "demo = gr.Blocks(gr.themes.Glass())\n",
    "\n",
    "with demo:\n",
    "    with gr.Row():\n",
    "        title = gr.Label(\"Real time audio transcription with OpenAI Whisper\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            audio_input = gr.Audio(source=\"microphone\", type=\"filepath\", format=\"wav\")\n",
    "        with gr.Column():\n",
    "            audio_transcription = gr.Textbox(label=\"Audio transcription\", interactive=True)\n",
    "    \n",
    "    audio_input.change(whisper_transcriber, inputs=audio_input, outputs=audio_transcription)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fruit-kb-QON9TVu_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
