{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_KEY  = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from converter.convert import mp4_to_wav\n",
    "from transcriber.transcribe import whisper_transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper\n",
    "def list_filepaths(directory):\n",
    "    filepaths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            filepaths.append(filepath)\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mp4 to WAV before transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data\\\\Call_1.mp4', '../data\\\\Call_2.mp4', '../data\\\\Call_3.mp4', '../data\\\\Call_4.mp4', '../data\\\\Call_5.mp4', '../data\\\\Call_6.mp4']\n"
     ]
    }
   ],
   "source": [
    "# Check list of files\n",
    "dir = \"../data\"\n",
    "filepaths = list_filepaths(dir)\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ../data\\Call_1.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_1.wav\n",
      "Converting ../data\\Call_2.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_2.wav\n",
      "Converting ../data\\Call_3.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_3.wav\n",
      "Converting ../data\\Call_4.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_4.wav\n",
      "Converting ../data\\Call_5.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_5.wav\n",
      "Converting ../data\\Call_6.mp4 to WAV...\n",
      "Conversion complete. WAV file saved at: ../data\\Call_6.wav\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepaths:\n",
    "    filename, extension = os.path.splitext(filepath)\n",
    "    if extension == \".mp4\":\n",
    "        wav_filepath = filename + \".wav\"\n",
    "\n",
    "        if not os.path.exists(wav_filepath):\n",
    "            # Perform conversion if there is no corresponding WAV file.\n",
    "            try:\n",
    "                wav_filepath = filename + \".wav\"\n",
    "                converted_audio = mp4_to_wav(filepath, wav_filepath, first_n_seconds=None)\n",
    "            except ValueError:\n",
    "                # Skip to next MP4 file that needs conversion\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data\\\\Call_1.mp4', '../data\\\\Call_1.wav', '../data\\\\Call_1_first_4min.wav', '../data\\\\Call_1_first_4min_transcription.txt', '../data\\\\Call_2.mp4', '../data\\\\Call_2.wav', '../data\\\\Call_2_first_4min.wav', '../data\\\\Call_2_first_4min_transcription.txt', '../data\\\\Call_3.mp4', '../data\\\\Call_3.wav', '../data\\\\Call_3_first_4min.wav', '../data\\\\Call_3_first_4min_transcription.txt', '../data\\\\Call_4.mp4', '../data\\\\Call_4.wav', '../data\\\\Call_4_first_4min.wav', '../data\\\\Call_4_first_4min_transcription.txt', '../data\\\\Call_5.mp4', '../data\\\\Call_5.wav', '../data\\\\Call_5_first_4min.wav', '../data\\\\Call_5_first_4min_transcription.txt', '../data\\\\Call_6.mp4', '../data\\\\Call_6.wav', '../data\\\\Call_6_first_4min.wav', '../data\\\\Call_6_first_4min_transcription.txt']\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data\"\n",
    "filepaths = list_filepaths(dir)\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing ../data\\Call_1.wav...\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Maximum content size limit (26214400) exceeded (26451714 bytes read) {\n  \"error\": {\n    \"message\": \"Maximum content size limit (26214400) exceeded (26451714 bytes read)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n} 413 {'error': {'message': 'Maximum content size limit (26214400) exceeded (26451714 bytes read)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 18 Jun 2024 15:32:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '171', 'Connection': 'keep-alive', 'openai-processing-ms': '571', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_08dfbd4bb4f223e6e825b0c1c6da4dac', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=tFURXoTlfYs1K0rki6.N5GS9ydyXd1ECdcThjjKwdRI-1718724748-1.0.1.1-mku3qza7TtpHae43Rebdh6DeriY.1qD.8FEcI73HLQ9l9tJ0uF2wBHo64CwlvenSYoPNqcuR_IsuUzQKOv9hpw; path=/; expires=Tue, 18-Jun-24 16:02:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=jIdvYjAwDh8ugkpU2nuQYfbyqUy9G4qQ61k6wOJUD.s-1718724748645-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '895c54d6ab9a04b6-HKG', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(transcription_path):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper_transcriber\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTRANSCRIPTION:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, transcription, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Open the file in write mode ('w' mode)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\audio_to_text\\transcriber\\transcribe.py:15\u001b[0m, in \u001b[0;36mwhisper_transcriber\u001b[1;34m(audio, api_key, type)\u001b[0m\n\u001b[0;32m     12\u001b[0m         audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, phrase_time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_whisper_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mUnknownValueError:\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\audio-to-text-Ba3M3CjB-py3.10\\lib\\site-packages\\speech_recognition\\recognizers\\whisper.py:41\u001b[0m, in \u001b[0;36mrecognize_whisper_api\u001b[1;34m(recognizer, audio_data, model, api_key)\u001b[0m\n\u001b[0;32m     38\u001b[0m wav_data \u001b[38;5;241m=\u001b[39m BytesIO(audio_data\u001b[38;5;241m.\u001b[39mget_wav_data())\n\u001b[0;32m     39\u001b[0m wav_data\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeechRecognition_audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 41\u001b[0m transcript \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transcript[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\audio-to-text-Ba3M3CjB-py3.10\\lib\\site-packages\\openai\\api_resources\\audio.py:67\u001b[0m, in \u001b[0;36mAudio.transcribe\u001b[1;34m(cls, model, file, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     55\u001b[0m requestor, files, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m     56\u001b[0m     file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m     57\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfile\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_url(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscriptions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mconvert_to_openai_object(\n\u001b[0;32m     69\u001b[0m     response, api_key, api_version, organization\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\audio-to-text-Ba3M3CjB-py3.10\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\audio-to-text-Ba3M3CjB-py3.10\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\canepomuceno\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\audio-to-text-Ba3M3CjB-py3.10\\lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAPIError\u001b[0m: Maximum content size limit (26214400) exceeded (26451714 bytes read) {\n  \"error\": {\n    \"message\": \"Maximum content size limit (26214400) exceeded (26451714 bytes read)\",\n    \"type\": \"server_error\",\n    \"param\": null,\n    \"code\": null\n  }\n} 413 {'error': {'message': 'Maximum content size limit (26214400) exceeded (26451714 bytes read)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 18 Jun 2024 15:32:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '171', 'Connection': 'keep-alive', 'openai-processing-ms': '571', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-reset-requests': '120ms', 'x-request-id': 'req_08dfbd4bb4f223e6e825b0c1c6da4dac', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=tFURXoTlfYs1K0rki6.N5GS9ydyXd1ECdcThjjKwdRI-1718724748-1.0.1.1-mku3qza7TtpHae43Rebdh6DeriY.1qD.8FEcI73HLQ9l9tJ0uF2wBHo64CwlvenSYoPNqcuR_IsuUzQKOv9hpw; path=/; expires=Tue, 18-Jun-24 16:02:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=jIdvYjAwDh8ugkpU2nuQYfbyqUy9G4qQ61k6wOJUD.s-1718724748645-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '895c54d6ab9a04b6-HKG', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "for filepath in filepaths:\n",
    "    filename, extension = os.path.splitext(filepath)\n",
    "    if extension == \".wav\":\n",
    "        # Specify the file path where you want to save the text file\n",
    "        transcription_path = f\"{filename}_transcription.txt\"\n",
    "\n",
    "        # Check if transcription already exists\n",
    "        if not os.path.exists(transcription_path):\n",
    "            print(f\"Transcribing {filepath}...\")\n",
    "            transcription = whisper_transcriber(filepath, api_key=OPENAI_API_KEY,\n",
    "                                                type=\"path\")\n",
    "            print(\"\\n\\nTRANSCRIPTION:\\n\", transcription, \"\\n\\n\")\n",
    "\n",
    "            # Open the file in write mode ('w' mode)\n",
    "            with open(transcription_path, 'w') as file:\n",
    "                # Write the string to the file\n",
    "                file.write(transcription)\n",
    "\n",
    "            print(f\"Transcription saved to {transcription_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fruit-kb-QON9TVu_-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
